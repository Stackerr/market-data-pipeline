#!/usr/bin/env python3
"""
ê¸°ì¡´ Parquet íŒŒì¼ì—ì„œ ìƒì¥íì§€ ì¢…ëª© ë°ì´í„°ë¥¼ ì½ì–´ ClickHouseì— ì—…ë°ì´íŠ¸
"""

import logging
import sys
from pathlib import Path
from datetime import datetime
import polars as pl

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.clickhouse.stock_master import ClickHouseStockMaster

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_delisted_from_parquet(parquet_path: Path) -> pl.DataFrame:
    """Parquet íŒŒì¼ì—ì„œ ìƒì¥íì§€ ì¢…ëª© ë°ì´í„° ë¡œë“œ"""
    logger.info(f"Loading delisted data from: {parquet_path}")

    if not parquet_path.exists():
        logger.error(f"Parquet file not found: {parquet_path}")
        return pl.DataFrame()

    try:
        df = pl.read_parquet(parquet_path)
        logger.info(f"âœ… Loaded {len(df)} records from parquet")
        logger.info(f"Columns: {df.columns}")
        return df
    except Exception as e:
        logger.error(f"Failed to load parquet file: {e}")
        return pl.DataFrame()


def map_delisted_columns(df: pl.DataFrame) -> pl.DataFrame:
    """ìƒì¥íì§€ ë°ì´í„° ì»¬ëŸ¼ì„ ClickHouse ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë§¤í•‘"""
    logger.info("Mapping columns to ClickHouse schema...")

    # ì»¬ëŸ¼ëª… ë§¤í•‘
    column_mapping = {
        'company_code': 'symbol',
        'company_name': 'name',
        'delisting_date': 'delisting_date',
        'delisting_reason': 'delisting_reason',
        'remarks': 'remarks'
    }

    # ê¸°ì¡´ ì»¬ëŸ¼ëª… í™•ì¸ ë° ë§¤í•‘
    mapped_df = df
    for old_col, new_col in column_mapping.items():
        if old_col in df.columns:
            mapped_df = mapped_df.rename({old_col: new_col})

    # ClickHouse ìŠ¤í‚¤ë§ˆì— ë§ëŠ” ì»¬ëŸ¼ ì¶”ê°€/ë³€í™˜
    if 'symbol' in mapped_df.columns:
        # ì¢…ëª©ì½”ë“œ ì •ë¦¬ (6ìë¦¬ ìˆ«ìë§Œ)
        mapped_df = mapped_df.with_columns(
            pl.col('symbol').cast(pl.String).str.replace_all(r'[^\d]', '').str.slice(0, 6).alias('symbol')
        )

        # 6ìë¦¬ê°€ ì•„ë‹Œ ì¢…ëª©ì½”ë“œ í•„í„°ë§
        mapped_df = mapped_df.filter(pl.col('symbol').str.len_chars() == 6)

    # í•„ìˆ˜ ì»¬ëŸ¼ ì¶”ê°€
    mapped_df = mapped_df.with_columns([
        pl.when(pl.col('name').is_null()).then(pl.lit("Unknown")).otherwise(pl.col('name')).alias('name'),
        pl.lit(None).alias('market').cast(pl.String),  # ì‹œì¥ ì •ë³´ëŠ” ë‚˜ì¤‘ì— ì¶”ë¡ 
        pl.lit(None).alias('listing_date').cast(pl.Date),
        pl.when(pl.col('delisting_date').is_null()).then(pl.date(2020, 1, 1)).otherwise(pl.col('delisting_date')).alias('delisting_date'),
        pl.lit(0).alias('is_active').cast(pl.UInt8)  # ìƒì¥íì§€ ì¢…ëª©ì€ ëª¨ë‘ ë¹„í™œì„±
    ])

    # ìµœì¢… ì»¬ëŸ¼ ì„ íƒ (ClickHouse stock_master ìŠ¤í‚¤ë§ˆì— ë§ì¶¤)
    final_df = mapped_df.select([
        'symbol',
        'name',
        'market',
        'listing_date',
        'delisting_date',
        'is_active'
    ])

    logger.info(f"âœ… Mapped to ClickHouse schema: {len(final_df)} records")
    return final_df


def infer_market_from_existing_data(stock_master: ClickHouseStockMaster, df: pl.DataFrame) -> pl.DataFrame:
    """ê¸°ì¡´ ClickHouse ë°ì´í„°ì—ì„œ ì‹œì¥ ì •ë³´ ì¶”ë¡ """
    logger.info("Inferring market information from existing data...")

    try:
        # ê¸°ì¡´ ìƒì¥ ì¢…ëª©ì—ì„œ ì‹œì¥ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        existing_df = stock_master.get_active_stocks()

        if existing_df.is_empty():
            logger.warning("No existing active stocks found for market inference")
            return df.with_columns(pl.lit("UNKNOWN").alias('market'))

        # ì¢…ëª©ì½”ë“œë¡œ ì¡°ì¸í•˜ì—¬ ì‹œì¥ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        market_lookup = existing_df.select(['symbol', 'market']).unique(subset=['symbol'])

        # Left joinìœ¼ë¡œ ì‹œì¥ ì •ë³´ ì¶”ê°€
        enhanced_df = df.join(market_lookup, on='symbol', how='left', suffix='_existing')

        # ì‹œì¥ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
        enhanced_df = enhanced_df.with_columns(
            pl.when(pl.col('market_existing').is_not_null())
            .then(pl.col('market_existing'))
            .otherwise(pl.lit("UNKNOWN"))
            .alias('market')
        ).drop('market_existing')

        market_stats = enhanced_df.group_by('market').agg(pl.count().alias('count'))
        logger.info("Market distribution after inference:")
        for row in market_stats.iter_rows(named=True):
            logger.info(f"  {row['market']}: {row['count']} stocks")

        return enhanced_df

    except Exception as e:
        logger.error(f"Failed to infer market information: {e}")
        return df.with_columns(pl.lit("UNKNOWN").alias('market'))


def insert_delisted_stocks(stock_master: ClickHouseStockMaster, df: pl.DataFrame) -> int:
    """ìƒì¥íì§€ ì¢…ëª©ì„ ClickHouseì— ì‚½ì…"""
    logger.info(f"Inserting {len(df)} delisted stocks to ClickHouse...")

    if df.is_empty():
        logger.warning("No data to insert")
        return 0

    try:
        # ê¸°ì¡´ ì¢…ëª©ê³¼ ì¤‘ë³µ ì²´í¬
        existing_symbols = set()
        try:
            all_existing = stock_master.get_active_stocks()
            delisted_existing = stock_master.get_delisted_stocks()

            if not all_existing.is_empty():
                existing_symbols.update(all_existing['symbol'].to_list())
            if not delisted_existing.is_empty():
                existing_symbols.update(delisted_existing['symbol'].to_list())

            logger.info(f"Found {len(existing_symbols)} existing symbols in ClickHouse")
        except Exception as e:
            logger.warning(f"Could not check existing symbols: {e}")

        # ìƒˆë¡œìš´ ì¢…ëª©ë§Œ í•„í„°ë§
        if existing_symbols:
            new_df = df.filter(~pl.col('symbol').is_in(list(existing_symbols)))
            logger.info(f"Filtered to {len(new_df)} new delisted stocks")
        else:
            new_df = df

        if new_df.is_empty():
            logger.info("No new delisted stocks to insert")
            return 0

        # ë°°ì¹˜ ì‚½ì…
        batch_size = 500
        total_inserted = 0

        for i in range(0, len(new_df), batch_size):
            batch_df = new_df.slice(i, batch_size)

            try:
                inserted_count = stock_master.insert_stocks(batch_df)
                total_inserted += inserted_count
                logger.info(f"Batch {i//batch_size + 1}: Inserted {inserted_count} stocks")
            except Exception as e:
                logger.error(f"Failed to insert batch {i//batch_size + 1}: {e}")

        return total_inserted

    except Exception as e:
        logger.error(f"Failed to insert delisted stocks: {e}")
        return 0


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("Starting delisted stocks update from parquet...")

    try:
        # ClickHouse ì—°ê²°
        stock_master = ClickHouseStockMaster()
        logger.info("ClickHouse connection established")

        # Parquet íŒŒì¼ ê²½ë¡œ
        parquet_path = project_root / "data" / "raw" / "delisted_stocks_processed_20250917.parquet"

        # 1. Parquet íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
        df = load_delisted_from_parquet(parquet_path)
        if df.is_empty():
            logger.error("No data loaded from parquet file")
            return False

        # 2. ì»¬ëŸ¼ ë§¤í•‘
        mapped_df = map_delisted_columns(df)

        # 3. ì‹œì¥ ì •ë³´ ì¶”ë¡ 
        enhanced_df = infer_market_from_existing_data(stock_master, mapped_df)

        # 4. ClickHouseì— ì‚½ì…
        inserted_count = insert_delisted_stocks(stock_master, enhanced_df)

        if inserted_count > 0:
            # 5. í…Œì´ë¸” ìµœì í™”
            logger.info("Optimizing table...")
            stock_master.optimize_table()

            # 6. ìµœì¢… í†µê³„
            stats = stock_master.get_stock_count()
            logger.info("ğŸ“Š Final statistics after update:")
            for market, counts in stats.items():
                logger.info(f"  {market}: {counts['active']} active, {counts['delisted']} delisted, {counts['total']} total")

            logger.info(f"âœ… Successfully updated {inserted_count} delisted stocks")
        else:
            logger.info("No new stocks were inserted")

        return True

    except Exception as e:
        logger.error(f"âŒ Failed to update delisted stocks: {e}")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)