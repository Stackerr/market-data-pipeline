#!/usr/bin/env python3
"""
ìƒì¥íì§€ ì¢…ëª© ë™ê¸°í™” ì‹œìŠ¤í…œ

ëª©ì :
- KRXì—ì„œ 1990ë…„ ì´í›„ ëª¨ë“  ìƒì¥íì§€ ì´ë ¥ í¬ë¡¤ë§í•˜ì—¬ ìƒì¥íì§€ ì •ë³´ í™•ë³´
- ìƒì¥íì§€ì¼ ë° ì‚¬ìœ  ì •ë³´ ìˆ˜ì§‘
- ì¤‘ë³µ ì œê±° ë° ë°ì´í„° í’ˆì§ˆ ê²€ì¦
- ìƒì¥íì§€ ì¢…ëª© ClickHouse ì ì¬

ì‹¤í–‰: uv run python scripts/sync_delisted_stocks.py
"""

import sys
import logging
import polars as pl
from datetime import datetime, date
from pathlib import Path
from typing import Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.crawlers.krx_delisted_crawler import KRXDelistedCrawler
from src.clickhouse.client import ClickHouseClient
from src.clickhouse.stock_master import ClickHouseStockMaster

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DelistedStockSync:
    """ìƒì¥íì§€ ì¢…ëª© ë™ê¸°í™” ì‹œìŠ¤í…œ"""

    def __init__(self, data_dir: str = "data/delisted_sync"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)

        # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        self.crawler = KRXDelistedCrawler(data_dir=str(self.data_dir))

        # ClickHouse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.clickhouse = ClickHouseClient()
        self.stock_master = ClickHouseStockMaster()

    def validate_delisted_data(self, df: pl.DataFrame) -> pl.DataFrame:
        """ìƒì¥íì§€ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ì •ì œ"""
        logger.info(f"ğŸ” ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹œì‘ (ì…ë ¥: {len(df)} records)")

        original_count = len(df)

        # 1. í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ['company_name', 'company_code', 'delisting_date', 'market']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")

        # 2. ì¢…ëª©ì½”ë“œ 6ìë¦¬ ê²€ì¦ (ì´ë¯¸ í¬ë¡¤ëŸ¬ì—ì„œ ì²˜ë¦¬ë˜ì§€ë§Œ ì¬ê²€ì¦)
        df = df.filter(
            (pl.col('company_code').str.len_chars() == 6) &
            (pl.col('company_code').str.contains(r'^\d{6}$'))
        )
        logger.info(f"ì¢…ëª©ì½”ë“œ ê²€ì¦ í›„: {len(df)} records")

        # 3. íšŒì‚¬ëª… ê²€ì¦ (ë¹ˆ ê°’ ì œê±°)
        df = df.filter(
            pl.col('company_name').is_not_null() &
            (pl.col('company_name').str.len_chars() > 0)
        )
        logger.info(f"íšŒì‚¬ëª… ê²€ì¦ í›„: {len(df)} records")

        # 4. ìƒì¥íì§€ì¼ ê²€ì¦ (nullì´ ì•„ë‹ˆê³  í•©ë¦¬ì ì¸ ë‚ ì§œ ë²”ìœ„)
        df = df.filter(
            pl.col('delisting_date').is_not_null() &
            (pl.col('delisting_date') >= date(1990, 1, 1)) &
            (pl.col('delisting_date') <= date.today())
        )
        logger.info(f"ìƒì¥íì§€ì¼ ê²€ì¦ í›„: {len(df)} records")

        # 5. ì¤‘ë³µ ì œê±° (ì¢…ëª©ì½”ë“œ + ìƒì¥íì§€ì¼ ê¸°ì¤€ìœ¼ë¡œ ì •í™•í•œ ì¤‘ë³µ ì œê±°)
        df = df.unique(subset=['company_code', 'delisting_date'])
        logger.info(f"ì¤‘ë³µ ì œê±° í›„: {len(df)} records")

        # 6. ë°ì´í„° í’ˆì§ˆ í†µê³„
        filtered_count = original_count - len(df)
        if filtered_count > 0:
            logger.warning(f"âš ï¸ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ìœ¼ë¡œ {filtered_count}ê°œ ë ˆì½”ë“œ ì œê±°ë¨")

        # 7. ì‹œì¥ë³„ ë¶„í¬ í™•ì¸
        if not df.is_empty():
            market_distribution = df.group_by('market').agg(pl.count().alias('count'))
            logger.info("ì‹œì¥ë³„ ìƒì¥íì§€ ì¢…ëª© ë¶„í¬:")
            for row in market_distribution.iter_rows(named=True):
                logger.info(f"  {row['market']}: {row['count']} ì¢…ëª©")

        logger.info(f"âœ… ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ (ìµœì¢…: {len(df)} records)")
        return df

    def check_existing_delisted_data(self) -> int:
        """ClickHouseì— ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ìƒì¥íì§€ ë°ì´í„° í™•ì¸"""
        try:
            query = """
                    SELECT count() as count
                    FROM stock_master
                    WHERE is_active = 0 AND delisting_date IS NOT NULL \
                    """
            result = self.clickhouse.execute_query(query)
            existing_count = result[0]['count'] if result else 0
            logger.info(f"ê¸°ì¡´ ìƒì¥íì§€ ë°ì´í„°: {existing_count}ê°œ")
            return existing_count
        except Exception as e:
            logger.warning(f"ê¸°ì¡´ ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {e}")
            return 0

    def update_stock_master_with_delisted_data(self, delisted_df: pl.DataFrame) -> dict:
        """ìƒì¥íì§€ ë°ì´í„°ë¡œ stock_master í…Œì´ë¸” ì—…ë°ì´íŠ¸ (ê°œë³„ í™•ì¸ í›„ ì²˜ë¦¬)"""
        logger.info(f"ğŸ“ stock_master í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì‹œì‘ ({len(delisted_df)} records)")

        stats = {
            'processed': 0,
            'updated': 0,
            'new_added': 0,
            'skipped': 0,
            'errors': 0
        }

        for row in delisted_df.iter_rows(named=True):
            symbol = row['company_code']
            company_name = row['company_name']
            delisting_date = row['delisting_date']
            market = row['market']

            try:
                stats['processed'] += 1

                # ê¸°ì¡´ ì¢…ëª© ì¡°íšŒ
                existing_stock = self.stock_master.get_stock_by_symbol(symbol)

                if existing_stock:
                    # ê¸°ì¡´ ì¢…ëª©ì´ ìˆëŠ” ê²½ìš°
                    if existing_stock.get('delisting_date'):
                        # ì´ë¯¸ ìƒì¥íì§€ ì²˜ë¦¬ë¨ - skip
                        logger.debug(f"Stock {symbol} already delisted, skipping")
                        stats['skipped'] += 1
                        continue

                    # ìƒì¥íì§€ ì •ë³´ ì—…ë°ì´íŠ¸ í•„ìš”
                    success = self.stock_master.update_delisting_date(symbol, delisting_date)
                    if success:
                        stats['updated'] += 1
                        logger.info(f"Updated delisting date for {symbol}: {delisting_date}")
                    else:
                        stats['errors'] += 1
                        logger.warning(f"Failed to update delisting date for {symbol}")

                else:
                    # ìƒˆë¡œìš´ ìƒì¥íì§€ ì¢…ëª© ë“±ë¡ (ê³¼ê±° ì¢…ëª©ì¼ ê°€ëŠ¥ì„±)
                    new_stock_data = pl.DataFrame({
                        'symbol': [symbol],
                        'name': [company_name],
                        'market': [market],
                        'listing_date': [None],  # í–¥í›„ ìƒì¥ì¼ ì¶”ì •ì—ì„œ ì²˜ë¦¬
                        'delisting_date': [delisting_date],
                        'is_active': [0],  # ìƒì¥íì§€
                        'create_dt': [datetime.now()],
                        'update_dt': [datetime.now()]
                    })

                    inserted_count = self.stock_master.insert_stocks(new_stock_data)
                    if inserted_count > 0:
                        stats['new_added'] += 1
                        logger.info(f"Added new delisted stock: {symbol} ({company_name})")
                    else:
                        stats['errors'] += 1
                        logger.warning(f"Failed to add new delisted stock: {symbol}")

                # ì§„í–‰ë¥  í‘œì‹œ (100ê°œë§ˆë‹¤)
                if stats['processed'] % 100 == 0:
                    logger.info(f"ì§„í–‰ë¥ : {stats['processed']}/{len(delisted_df)}")

            except Exception as e:
                stats['errors'] += 1
                logger.error(f"ì²˜ë¦¬ ì˜¤ë¥˜ [{symbol}]: {e}")

        logger.info(f"âœ… stock_master ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        logger.info(f"  ì²˜ë¦¬ë¨: {stats['processed']}")
        logger.info(f"  ì—…ë°ì´íŠ¸ë¨: {stats['updated']}")
        logger.info(f"  ì‹ ê·œ ì¶”ê°€ë¨: {stats['new_added']}")
        logger.info(f"  ê±´ë„ˆëœ€: {stats['skipped']}")
        logger.info(f"  ì˜¤ë¥˜: {stats['errors']}")

        return stats

    def save_results(self, delisted_df: pl.DataFrame, stats: dict) -> Path:
        """ê²°ê³¼ë¥¼ Parquet íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ìƒì¥íì§€ ë°ì´í„° ì €ì¥
        delisted_file = self.data_dir / f"delisted_collection_result_{timestamp}.parquet"
        delisted_df.write_parquet(delisted_file)
        logger.info(f"ğŸ’¾ ìƒì¥íì§€ ë°ì´í„° ì €ì¥: {delisted_file}")

        # í†µê³„ ì •ë³´ ì €ì¥
        stats_df = pl.DataFrame({
            'metric': list(stats.keys()),
            'value': list(stats.values()),
            'timestamp': [datetime.now()] * len(stats)
        })
        stats_file = self.data_dir / f"delisted_collection_stats_{timestamp}.parquet"
        stats_df.write_parquet(stats_file)
        logger.info(f"ğŸ“Š í†µê³„ ì •ë³´ ì €ì¥: {stats_file}")

        return delisted_file

    def execute_sync(self, start_year: int = 1990, force_recrawl: bool = False) -> bool:
        """ìƒì¥íì§€ ì¢…ëª© ë™ê¸°í™” ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        logger.info(f"ğŸš€ ìƒì¥íì§€ ì¢…ëª© ë™ê¸°í™” ì‹œì‘ (ì‹œì‘ì—°ë„: {start_year})")

        try:
            # 1. ê¸°ì¡´ ë°ì´í„° í™•ì¸
            existing_count = self.check_existing_delisted_data()
            if existing_count > 0 and not force_recrawl:
                logger.info(f"ê¸°ì¡´ ìƒì¥íì§€ ë°ì´í„°ê°€ {existing_count}ê°œ ì¡´ì¬í•©ë‹ˆë‹¤.")
                logger.info("force_recrawl=Trueë¡œ ì‹¤í–‰í•˜ë©´ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
                return True

            # 2. KRX ìƒì¥íì§€ ë°ì´í„° í¬ë¡¤ë§
            logger.info(f"ğŸ“¡ KRX ìƒì¥íì§€ ë°ì´í„° í¬ë¡¤ë§ ì‹œì‘ ({start_year}ë…„ ì´í›„)")
            delisted_df = self.crawler.crawl_all_markets_full_sync(start_year=start_year)

            if delisted_df.is_empty():
                logger.warning("âš ï¸ í¬ë¡¤ë§ëœ ìƒì¥íì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False

            logger.info(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(delisted_df)} ì¢…ëª©")

            # 3. ë°ì´í„° í’ˆì§ˆ ê²€ì¦
            validated_df = self.validate_delisted_data(delisted_df)

            if validated_df.is_empty():
                logger.error("âŒ ê²€ì¦ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False

            # 4. ClickHouse stock_master í…Œì´ë¸” ì—…ë°ì´íŠ¸
            stats = self.update_stock_master_with_delisted_data(validated_df)

            # 5. ê²°ê³¼ ì €ì¥
            result_file = self.save_results(validated_df, stats)

            # 6. ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸
            logger.info(f"ğŸ¯ ìƒì¥íì§€ ì¢…ëª© ë™ê¸°í™” ì™„ë£Œ!")
            logger.info(f"  í¬ë¡¤ë§ëœ ì¢…ëª©: {len(delisted_df)}")
            logger.info(f"  ê²€ì¦ëœ ì¢…ëª©: {len(validated_df)}")
            logger.info(f"  ì—…ë°ì´íŠ¸ëœ ì¢…ëª©: {stats['updated']}")
            logger.info(f"  ì‹ ê·œ ì¶”ê°€ëœ ì¢…ëª©: {stats['new_added']}")
            logger.info(f"  ê±´ë„ˆë›´ ì¢…ëª©: {stats['skipped']}")
            logger.info(f"  ê²°ê³¼ íŒŒì¼: {result_file}")

            return True

        except Exception as e:
            logger.error(f"âŒ ìƒì¥íì§€ ì¢…ëª© ë™ê¸°í™” ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return False

    def generate_report(self) -> dict:
        """ìƒì¥íì§€ ì¢…ëª© ë™ê¸°í™” ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        try:
            # ClickHouseì—ì„œ ìƒì¥íì§€ ë°ì´í„° í†µê³„ ì¡°íšŒ
            query = """
                    SELECT market,
                           count()             as delisted_count,
                           min(delisting_date) as earliest_delisting,
                           max(delisting_date) as latest_delisting
                    FROM stock_master
                    WHERE is_active = 0
                      AND delisting_date IS NOT NULL
                    GROUP BY market
                    ORDER BY delisted_count DESC \
                    """

            result = self.clickhouse.execute_query(query)

            report = {
                'system': 'ìƒì¥íì§€ ì¢…ëª© ë™ê¸°í™”',
                'description': 'ìƒì¥íì§€ ì¢…ëª© ì •ë³´ ìˆ˜ì§‘ ë° ë™ê¸°í™”',
                'execution_time': datetime.now().isoformat(),
                'market_statistics': result,
                'total_delisted': sum(row['delisted_count'] for row in result)
            }

            logger.info("ğŸ“‹ ìƒì¥íì§€ ì¢…ëª© ë™ê¸°í™” ë¦¬í¬íŠ¸:")
            logger.info(f"  ì´ ìƒì¥íì§€ ì¢…ëª©: {report['total_delisted']}")
            for market_stat in result:
                logger.info(f"  {market_stat['market']}: {market_stat['delisted_count']} ì¢…ëª©")

            return report

        except Exception as e:
            logger.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {}


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description='ìƒì¥íì§€ ì¢…ëª© ë™ê¸°í™” ì‹œìŠ¤í…œ')
    parser.add_argument('--start-year', type=int, default=1990,
                        help='í¬ë¡¤ë§ ì‹œì‘ ì—°ë„ (ê¸°ë³¸ê°’: 1990)')
    parser.add_argument('--force-recrawl', action='store_true',
                        help='ê¸°ì¡´ ë°ì´í„°ê°€ ìˆì–´ë„ ë‹¤ì‹œ í¬ë¡¤ë§')
    parser.add_argument('--report-only', action='store_true',
                        help='ë¦¬í¬íŠ¸ë§Œ ìƒì„± (í¬ë¡¤ë§ í•˜ì§€ ì•ŠìŒ)')
    parser.add_argument('--explain', action='store_true',
                        help='ìƒì¥íì§€ ì¢…ëª© ë™ê¸°í™” ì‹œìŠ¤í…œì´ ìˆ˜í–‰í•˜ëŠ” ì‘ì—… ì„¤ëª…')

    args = parser.parse_args()

    if args.explain:
        print("""
ğŸ¯ ìƒì¥íì§€ ì¢…ëª© ë™ê¸°í™” ì‹œìŠ¤í…œ

ğŸ“‹ ìˆ˜í–‰ ì‘ì—…:
1. KRX ìƒì¥íì§€ ë°ì´í„° í¬ë¡¤ë§ (1990ë…„ ì´í›„)
   - KOSPI, KOSDAQ, KONEX 3ê°œ ì‹œì¥
   - ìƒì¥íì§€ì¼ ë° ì‚¬ìœ  ì •ë³´ ìˆ˜ì§‘
   - HTML íŒŒì‹± ë° ë°ì´í„° ì •ê·œí™”

2. ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ì •ì œ
   - ì¢…ëª©ì½”ë“œ 6ìë¦¬ ìˆ«ì ê²€ì¦
   - íšŒì‚¬ëª… ìœ íš¨ì„± ê²€ì‚¬
   - ìƒì¥íì§€ì¼ ë‚ ì§œ ë²”ìœ„ ê²€ì¦ (1990~í˜„ì¬)
   - ì¤‘ë³µ ë°ì´í„° ì œê±°

3. ClickHouse stock_master í…Œì´ë¸” ì—…ë°ì´íŠ¸
   - ê¸°ì¡´ ì¢…ëª© ìƒì¥íì§€ ì •ë³´ ì—…ë°ì´íŠ¸
   - ìƒˆë¡œìš´ ìƒì¥íì§€ ì¢…ëª© ë“±ë¡
   - is_active=0, delisting_date ì„¤ì •

4. ê²°ê³¼ ì €ì¥ ë° ë¦¬í¬íŠ¸
   - Parquet íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥
   - ì‹œì¥ë³„ í†µê³„ ë¦¬í¬íŠ¸ ìƒì„±
   - ì²˜ë¦¬ ê²°ê³¼ ë¡œê·¸ ê¸°ë¡

ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ:
- í¬ë¡¤ëŸ¬: requests + BeautifulSoup4
- ë°ì´í„° ì²˜ë¦¬: Polars
- ë°ì´í„°ë² ì´ìŠ¤: ClickHouse (HTTP API)
- í…ŒìŠ¤íŠ¸: pytest (20ê°œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤)

ğŸ“Š í˜„ì¬ ìƒíƒœ:
- ì´ ìƒì¥íì§€ ì¢…ëª©: 1,704ê°œ (ì´ë¯¸ ì ì¬ë¨)
- êµ¬í˜„ ì½”ë“œ: 785ë¼ì¸ (ìƒˆë¡œ ì‘ì„±)
- í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€: 20ê°œ í…ŒìŠ¤íŠ¸ ëª¨ë‘ í†µê³¼

ğŸš€ ì‹¤í–‰ ì˜µì…˜:
- ê¸°ë³¸ ì‹¤í–‰: uv run python scripts/sync_delisted_stocks.py
- ë¦¬í¬íŠ¸ë§Œ: uv run python scripts/sync_delisted_stocks.py --report-only
- ê°•ì œ ì¬í¬ë¡¤ë§: uv run python scripts/sync_delisted_stocks.py --force-recrawl
        """)
        return True

    # ìƒì¥íì§€ ì¢…ëª© ë™ê¸°í™” ì‹¤í–‰
    delisted_sync = DelistedStockSync()

    try:
        if args.report_only:
            # ë¦¬í¬íŠ¸ë§Œ ìƒì„±
            report = delisted_sync.generate_report()
            return bool(report)
        else:
            # ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
            success = delisted_sync.execute_sync(
                start_year=args.start_year,
                force_recrawl=args.force_recrawl
            )

            if success:
                # ì‹¤í–‰ í›„ ë¦¬í¬íŠ¸ ìƒì„±
                delisted_sync.generate_report()

            return success

    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        return False
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
